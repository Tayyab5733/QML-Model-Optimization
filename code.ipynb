{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pennylane optax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "import jax\n",
    "from jax import numpy as jnp\n",
    "import optax\n",
    "\n",
    "n_wires = 5\n",
    "data = jnp.cos(jnp.mgrid[-2:2:0.2].reshape(n_wires, -1)) ** 3\n",
    "targets = jnp.array([-0.2, 0.4, 0.35, 0.2])\n",
    "\n",
    "dev = qml.device(\"default.qubit\", wires=n_wires)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def circuit(data, weights):\n",
    "    \"\"\"Quantum circuit ansatz\"\"\"\n",
    "\n",
    "    # data embedding\n",
    "    for i in range(n_wires):\n",
    "        # data[i] will be of shape (4,); we are\n",
    "        # taking advantage of operation vectorization here\n",
    "        qml.RY(data[i], wires=i)\n",
    "\n",
    "    # trainable ansatz\n",
    "    for i in range(n_wires):\n",
    "        qml.RX(weights[i, 0], wires=i)\n",
    "        qml.RY(weights[i, 1], wires=i)\n",
    "        qml.RX(weights[i, 2], wires=i)\n",
    "        qml.CNOT(wires=[i, (i + 1) % n_wires])\n",
    "\n",
    "    # we use a sum of local Z's as an observable since a\n",
    "    # local Z would only be affected by params on that qubit.\n",
    "    return qml.expval(qml.sum(*[qml.PauliZ(i) for i in range(n_wires)]))\n",
    "\n",
    "def my_model(data, weights, bias):\n",
    "    return circuit(data, weights) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def loss_fn(params, data, targets):\n",
    "    predictions = my_model(data, params[\"weights\"], params[\"bias\"])\n",
    "    loss = jnp.sum((targets - predictions) ** 2 / len(data))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = jnp.ones([n_wires, 3])\n",
    "bias = jnp.array(0.)\n",
    "params = {\"weights\": weights, \"bias\": bias}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17344648\n",
      "{'bias': Array(-0.65765524, dtype=float32, weak_type=True), 'weights': Array([[-0.17739275, -0.06189498, -0.17819384],\n",
      "       [-0.21560565, -0.0275434 , -0.33223915],\n",
      "       [-0.0020373 ,  0.09686179, -0.23871091],\n",
      "       [-0.15701011, -0.00134047, -0.2873454 ],\n",
      "       [-0.0184525 , -0.0064371 , -0.01853886]], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "print(loss_fn(params, data, targets))\n",
    "print(jax.grad(loss_fn)(params, data, targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optax.adam(learning_rate=0.3)\n",
    "opt_state = opt.init(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 Loss: 0.17344647645950317\n",
      "Step: 5 Loss: 0.14710889756679535\n",
      "Step: 10 Loss: 0.05850798636674881\n",
      "Step: 15 Loss: 0.04570798948407173\n",
      "Step: 20 Loss: 0.03201589733362198\n",
      "Step: 25 Loss: 0.02616313472390175\n",
      "Step: 30 Loss: 0.024366136640310287\n",
      "Step: 35 Loss: 0.022175978869199753\n",
      "Step: 40 Loss: 0.02028464339673519\n",
      "Step: 45 Loss: 0.019171901047229767\n",
      "Step: 50 Loss: 0.018599100410938263\n",
      "Step: 55 Loss: 0.01829129084944725\n",
      "Step: 60 Loss: 0.018130116164684296\n",
      "Step: 65 Loss: 0.017963577061891556\n",
      "Step: 70 Loss: 0.01769602671265602\n",
      "Step: 75 Loss: 0.01737845502793789\n",
      "Step: 80 Loss: 0.017195910215377808\n",
      "Step: 85 Loss: 0.016997545957565308\n",
      "Step: 90 Loss: 0.01689930260181427\n",
      "Step: 95 Loss: 0.01683393120765686\n"
     ]
    }
   ],
   "source": [
    "def update_step(opt, params, opt_state, data, targets):\n",
    "    loss_val, grads = jax.value_and_grad(loss_fn)(params, data, targets)\n",
    "    updates, opt_state = opt.update(grads, opt_state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    return params, opt_state, loss_val\n",
    "\n",
    "loss_history = []\n",
    "\n",
    "for i in range(100):\n",
    "    params, opt_state, loss_val = update_step(opt, params, opt_state, data, targets)\n",
    "\n",
    "    if i % 5 == 0:\n",
    "        print(f\"Step: {i} Loss: {loss_val}\")\n",
    "\n",
    "    loss_history.append(loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer we want to work with\n",
    "opt = optax.adam(learning_rate=0.3)\n",
    "\n",
    "@jax.jit\n",
    "def update_step_jit(i, args):\n",
    "    params, opt_state, data, targets, print_training = args\n",
    "\n",
    "    loss_val, grads = jax.value_and_grad(loss_fn)(params, data, targets)\n",
    "    updates, opt_state = opt.update(grads, opt_state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "\n",
    "    def print_fn():\n",
    "        jax.debug.print(\"Step: {i}  Loss: {loss_val}\", i=i, loss_val=loss_val)\n",
    "\n",
    "    # if print_training=True, print the loss every 5 steps\n",
    "    jax.lax.cond((jnp.mod(i, 5) == 0) & print_training, print_fn, lambda: None)\n",
    "\n",
    "    return (params, opt_state, data, targets, print_training)\n",
    "\n",
    "@jax.jit\n",
    "def optimization_jit(params, data, targets, print_training=False):\n",
    "\n",
    "    opt_state = opt.init(params)\n",
    "    args = (params, opt_state, data, targets, print_training)\n",
    "    (params, opt_state, _, _, _) = jax.lax.fori_loop(0, 100, update_step_jit, args)\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0  Loss: 0.17344647645950317\n",
      "Step: 5  Loss: 0.14710880815982819\n",
      "Step: 10  Loss: 0.05850811302661896\n",
      "Step: 15  Loss: 0.045708067715168\n",
      "Step: 20  Loss: 0.03201604634523392\n",
      "Step: 25  Loss: 0.02616310305893421\n",
      "Step: 30  Loss: 0.024366099387407303\n",
      "Step: 35  Loss: 0.022175926715135574\n",
      "Step: 40  Loss: 0.020284635946154594\n",
      "Step: 45  Loss: 0.01917184703052044\n",
      "Step: 50  Loss: 0.018599100410938263\n",
      "Step: 55  Loss: 0.01829131320118904\n",
      "Step: 60  Loss: 0.01813017763197422\n",
      "Step: 65  Loss: 0.017963571473956108\n",
      "Step: 70  Loss: 0.017696011811494827\n",
      "Step: 75  Loss: 0.017378445714712143\n",
      "Step: 80  Loss: 0.01719590835273266\n",
      "Step: 85  Loss: 0.016997555270791054\n",
      "Step: 90  Loss: 0.01689927838742733\n",
      "Step: 95  Loss: 0.01683397963643074\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bias': Array(0.01127004, dtype=float32),\n",
       " 'weights': Array([[1.2887369 , 2.0005755 , 0.99289083],\n",
       "        [1.6590643 , 1.3155318 , 1.2168641 ],\n",
       "        [1.4232814 , 0.2568506 , 1.7053303 ],\n",
       "        [1.2973213 , 1.880504  , 0.85184103],\n",
       "        [0.05557076, 3.3709753 , 3.1788893 ]], dtype=float32)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\"weights\": weights, \"bias\": bias}\n",
    "optimization_jit(params, data, targets, print_training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jitting just the cost (best of 5): 0.6283237499992538 sec per loop\n",
      "Jitting the entire optimization (best of 5): 0.0019953500013798475 sec per loop\n"
     ]
    }
   ],
   "source": [
    "from timeit import repeat\n",
    "\n",
    "def optimization(params, data, targets):\n",
    "    opt = optax.adam(learning_rate=0.3)\n",
    "    opt_state = opt.init(params)\n",
    "\n",
    "    for i in range(100):\n",
    "        params, opt_state, loss_val = update_step(opt, params, opt_state, data, targets)\n",
    "\n",
    "    return params\n",
    "\n",
    "reps = 5\n",
    "num = 2\n",
    "\n",
    "times = repeat(\"optimization(params, data, targets)\", globals=globals(), number=num, repeat=reps)\n",
    "result = min(times) / num\n",
    "\n",
    "print(f\"Jitting just the cost (best of {reps}): {result} sec per loop\")\n",
    "\n",
    "times = repeat(\"optimization_jit(params, data, targets)\", globals=globals(), number=num, repeat=reps)\n",
    "result = min(times) / num\n",
    "\n",
    "print(f\"Jitting the entire optimization (best of {reps}): {result} sec per loop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-7.2067559e-02 -1.1728344e-02 -2.4895622e-05  4.9101636e-03]\n",
      " [ 4.7578786e-02  1.5772879e-01  3.3818188e-01  5.6220156e-01]\n",
      " [ 7.8138560e-01  9.4138408e-01  1.0000000e+00  9.4138354e-01]\n",
      " [ 7.8138465e-01  5.6220043e-01  3.3818090e-01  1.5772806e-01]\n",
      " [ 4.7578432e-02  4.9100821e-03 -2.4898063e-05 -1.1728490e-02]]\n"
     ]
    }
   ],
   "source": [
    "n_wires = 5\n",
    "data = jnp.cos(jnp.mgrid[-2:2:0.2].reshape(n_wires, -1)) ** 3\n",
    "targets = jnp.array([-0.2, 0.4, 0.35, 0.2])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
